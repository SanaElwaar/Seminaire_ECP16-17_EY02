{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup \n",
    "import pickle\n",
    "import json\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentimentDictionary=\"AFINN.json\"\n",
    "labeledbasefile=\"raw_data/reviews.p\"\n",
    "with open(sentimentDictionary, \"r\") as rFile:\n",
    "        sDictionary=rFile.read()\n",
    "Sdict=json.loads(sDictionary)  \n",
    "\n",
    "for k in Sdict.keys():\n",
    "    Sdict[k]=Sdict[k]+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D= pickle.load(open( labeledbasefile, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews=D[D['review_content']!='']\n",
    "reviews = reviews.reset_index(drop=True)\n",
    "reviews=reviews[[\"review_content\",\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_Accents={\"\\xea\":\"e\",\"\\xe9\":\"e\",\"\\xe8\":\"e\",\"\\xe0\":\"a\",\"\\xfb\":\"u\",\"\\xf1\":\"n\",\"\\xf2\":\"o\",\"\\xf3\":\"o\",\"\\xf4\":\"o\",\"\\xf5\":\"o\",\"\\xf6\":\"o\"}\n",
    "for i in D_Accents.keys():\n",
    "    reviews['review_content']=reviews['review_content'].apply(lambda x: re.sub(i,D_Accents[i],x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ca serait plutot un film tres bien si ils ont ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un univers unique, une melodie immortelle, une...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je pense que compte-tenu de la rarete de ce fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un film super top, une excellente surprise, dr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA, annees 80/90. Un publicitaire Americain a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_content  Target\n",
       "0  Ca serait plutot un film tres bien si ils ont ...       0\n",
       "1  Un univers unique, une melodie immortelle, une...       0\n",
       "2  Je pense que compte-tenu de la rarete de ce fi...       0\n",
       "3  un film super top, une excellente surprise, dr...       0\n",
       "4  USA, annees 80/90. Un publicitaire Americain a...       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "fr_stopwords = set(stopwords.words('french')+['les'])\n",
    "for i in D_Accents.keys():\n",
    "    fr_stopwords=[re.sub(i,D_Accents[i],x) for x in fr_stopwords]\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "st = FrenchStemmer(ignore_stopwords=True)\n",
    "\n",
    "def count_negation(x):\n",
    "    d=[\"non\",\"pas\",\"contrairement\",\"jamais\"]\n",
    "    c=0\n",
    "    for t in x.split():\n",
    "        if t in d:\n",
    "            c=+1\n",
    "    return c\n",
    "\n",
    "def neg_words(x):\n",
    "    l=len(x.split())\n",
    "    c=0\n",
    "    for t in x.split():\n",
    "        if (t in Sdict):\n",
    "            if Sdict[t]<5:\n",
    "                c=+1\n",
    "    if l==0:\n",
    "        return 0\n",
    "    return float(c)/l\n",
    "\n",
    "def pos_words(x):\n",
    "    l=len(x.split())\n",
    "    c=0\n",
    "    for t in x.split():\n",
    "        if (t in Sdict):\n",
    "            if Sdict[t]>5:\n",
    "                c=+1\n",
    "    if l==0:\n",
    "        return 0\n",
    "    return float(c)/l\n",
    "\n",
    "def sentiment_score_lexicon(x):\n",
    "    s=0\n",
    "    n=0\n",
    "    for t in x.split():\n",
    "        if t in Sdict:\n",
    "            s=+Sdict[t]\n",
    "            n=+1\n",
    "    if n==0:\n",
    "        return 0\n",
    "    return float(s)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews[\"review_relevant\"]=reviews[\"review_content\"].apply(lambda x: \" \".join([t for t in x.split() if t not in fr_stopwords]))\n",
    "reviews[\"review_stemmed\"]=reviews[\"review_relevant\"].apply(lambda x: st.stem(x))\n",
    "reviews[\"review_length\"]=reviews[\"review_relevant\"].apply(lambda x: len(x))\n",
    "reviews[\"review_neg\"]=reviews[\"review_content\"].apply(lambda x: count_negation(x))\n",
    "reviews[\"review_neg_words\"]=reviews[\"review_content\"].apply(lambda x: neg_words(x))\n",
    "reviews[\"review_pos_words\"]=reviews[\"review_content\"].apply(lambda x: pos_words(x))\n",
    "reviews[\"review_Lexicon_score\"]=reviews[\"review_content\"].apply(lambda x: sentiment_score_lexicon(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>Target</th>\n",
       "      <th>review_relevant</th>\n",
       "      <th>review_stemmed</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_neg</th>\n",
       "      <th>review_neg_words</th>\n",
       "      <th>review_pos_words</th>\n",
       "      <th>review_Lexicon_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ca serait plutot un film tres bien si ils ont ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ca plutot film tres bien si ils engager Richar...</td>\n",
       "      <td>ca plutot film tres bien si ils engager richar...</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un univers unique, une melodie immortelle, une...</td>\n",
       "      <td>0</td>\n",
       "      <td>Un univers unique, melodie immortelle, oeuvre ...</td>\n",
       "      <td>un univers unique, melodie immortelle, oeuvre ...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je pense que compte-tenu de la rarete de ce fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Je pense compte-tenu rarete film, prix ici der...</td>\n",
       "      <td>je pense compte-tenu rarete film, prix ici der...</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un film super top, une excellente surprise, dr...</td>\n",
       "      <td>0</td>\n",
       "      <td>film super top, excellente surprise, drole ins...</td>\n",
       "      <td>film super top, excellente surprise, drole ins...</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA, annees 80/90. Un publicitaire Americain a...</td>\n",
       "      <td>1</td>\n",
       "      <td>USA, annees 80/90. Un publicitaire Americain c...</td>\n",
       "      <td>usa, annees 80/90. un publicitaire americain c...</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_content  Target  \\\n",
       "0  Ca serait plutot un film tres bien si ils ont ...       0   \n",
       "1  Un univers unique, une melodie immortelle, une...       0   \n",
       "2  Je pense que compte-tenu de la rarete de ce fi...       0   \n",
       "3  un film super top, une excellente surprise, dr...       0   \n",
       "4  USA, annees 80/90. Un publicitaire Americain a...       1   \n",
       "\n",
       "                                     review_relevant  \\\n",
       "0  Ca plutot film tres bien si ils engager Richar...   \n",
       "1  Un univers unique, melodie immortelle, oeuvre ...   \n",
       "2  Je pense compte-tenu rarete film, prix ici der...   \n",
       "3  film super top, excellente surprise, drole ins...   \n",
       "4  USA, annees 80/90. Un publicitaire Americain c...   \n",
       "\n",
       "                                      review_stemmed  review_length  \\\n",
       "0  ca plutot film tres bien si ils engager richar...            155   \n",
       "1  un univers unique, melodie immortelle, oeuvre ...            453   \n",
       "2  je pense compte-tenu rarete film, prix ici der...            243   \n",
       "3  film super top, excellente surprise, drole ins...            172   \n",
       "4  usa, annees 80/90. un publicitaire americain c...            187   \n",
       "\n",
       "   review_neg  review_neg_words  review_pos_words  review_Lexicon_score  \n",
       "0           1          0.000000          0.030303                  10.0  \n",
       "1           0          0.010753          0.000000                   3.0  \n",
       "2           0          0.000000          0.020833                   8.0  \n",
       "3           0          0.000000          0.029412                   8.0  \n",
       "4           0          0.000000          0.000000                   0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pattern.fr import parse, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['comment_tokens'] = reviews['review_content'].apply(lambda x: parse(x, chunks = False, lemmata = True).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews['comment_lemmas'] = reviews['comment_tokens'].apply(lambda x: \" \".join([t[2] for t in x ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "      <th>Target</th>\n",
       "      <th>review_relevant</th>\n",
       "      <th>review_stemmed</th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_neg</th>\n",
       "      <th>review_neg_words</th>\n",
       "      <th>review_pos_words</th>\n",
       "      <th>review_Lexicon_score</th>\n",
       "      <th>comment_tokens</th>\n",
       "      <th>comment_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ca serait plutot un film tres bien si ils ont ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Ca plutot film tres bien si ils engager Richar...</td>\n",
       "      <td>ca plutot film tres bien si ils engager richar...</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>10.0</td>\n",
       "      <td>[[Ca, VB, cer], [serait, VB, être], [plutot, N...</td>\n",
       "      <td>cer être plutot un film tre bien si il avoir p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un univers unique, une melodie immortelle, une...</td>\n",
       "      <td>0</td>\n",
       "      <td>Un univers unique, melodie immortelle, oeuvre ...</td>\n",
       "      <td>un univers unique, melodie immortelle, oeuvre ...</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[[Un, DT, un], [univers, NN, univers], [unique...</td>\n",
       "      <td>un univers unique , une melodie immortel , une...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Je pense que compte-tenu de la rarete de ce fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Je pense compte-tenu rarete film, prix ici der...</td>\n",
       "      <td>je pense compte-tenu rarete film, prix ici der...</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[[Je, PRP, je], [pense, VB, penser], [que, IN,...</td>\n",
       "      <td>je penser que compte-tenu de la rarete de ce f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>un film super top, une excellente surprise, dr...</td>\n",
       "      <td>0</td>\n",
       "      <td>film super top, excellente surprise, drole ins...</td>\n",
       "      <td>film super top, excellente surprise, drole ins...</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>8.0</td>\n",
       "      <td>[[un, DT, un], [film, NN, film], [super, NN, s...</td>\n",
       "      <td>un film super top , une excellent surprise , d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USA, annees 80/90. Un publicitaire Americain a...</td>\n",
       "      <td>1</td>\n",
       "      <td>USA, annees 80/90. Un publicitaire Americain c...</td>\n",
       "      <td>usa, annees 80/90. un publicitaire americain c...</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[USA, NNPS, usa], [,, ,, ,], [annees, NNS, an...</td>\n",
       "      <td>usa , annee 80 .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_content  Target  \\\n",
       "0  Ca serait plutot un film tres bien si ils ont ...       0   \n",
       "1  Un univers unique, une melodie immortelle, une...       0   \n",
       "2  Je pense que compte-tenu de la rarete de ce fi...       0   \n",
       "3  un film super top, une excellente surprise, dr...       0   \n",
       "4  USA, annees 80/90. Un publicitaire Americain a...       1   \n",
       "\n",
       "                                     review_relevant  \\\n",
       "0  Ca plutot film tres bien si ils engager Richar...   \n",
       "1  Un univers unique, melodie immortelle, oeuvre ...   \n",
       "2  Je pense compte-tenu rarete film, prix ici der...   \n",
       "3  film super top, excellente surprise, drole ins...   \n",
       "4  USA, annees 80/90. Un publicitaire Americain c...   \n",
       "\n",
       "                                      review_stemmed  review_length  \\\n",
       "0  ca plutot film tres bien si ils engager richar...            155   \n",
       "1  un univers unique, melodie immortelle, oeuvre ...            453   \n",
       "2  je pense compte-tenu rarete film, prix ici der...            243   \n",
       "3  film super top, excellente surprise, drole ins...            172   \n",
       "4  usa, annees 80/90. un publicitaire americain c...            187   \n",
       "\n",
       "   review_neg  review_neg_words  review_pos_words  review_Lexicon_score  \\\n",
       "0           1          0.000000          0.030303                  10.0   \n",
       "1           0          0.010753          0.000000                   3.0   \n",
       "2           0          0.000000          0.020833                   8.0   \n",
       "3           0          0.000000          0.029412                   8.0   \n",
       "4           0          0.000000          0.000000                   0.0   \n",
       "\n",
       "                                      comment_tokens  \\\n",
       "0  [[Ca, VB, cer], [serait, VB, être], [plutot, N...   \n",
       "1  [[Un, DT, un], [univers, NN, univers], [unique...   \n",
       "2  [[Je, PRP, je], [pense, VB, penser], [que, IN,...   \n",
       "3  [[un, DT, un], [film, NN, film], [super, NN, s...   \n",
       "4  [[USA, NNPS, usa], [,, ,, ,], [annees, NNS, an...   \n",
       "\n",
       "                                      comment_lemmas  \n",
       "0  cer être plutot un film tre bien si il avoir p...  \n",
       "1  un univers unique , une melodie immortel , une...  \n",
       "2  je penser que compte-tenu de la rarete de ce f...  \n",
       "3  un film super top , une excellent surprise , d...  \n",
       "4                                   usa , annee 80 .  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Modèles simples: des features basiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_length</th>\n",
       "      <th>review_neg</th>\n",
       "      <th>review_neg_words</th>\n",
       "      <th>review_pos_words</th>\n",
       "      <th>review_Lexicon_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13373</th>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29862</th>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28123</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_length  review_neg  review_neg_words  review_pos_words  \\\n",
       "13373            275           0          0.014286          0.014286   \n",
       "4056              65           0          0.000000          0.000000   \n",
       "29862            276           0          0.014286          0.014286   \n",
       "7221             134           1          0.000000          0.045455   \n",
       "28123             52           0          0.000000          0.111111   \n",
       "\n",
       "       review_Lexicon_score  \n",
       "13373                   4.0  \n",
       "4056                    0.0  \n",
       "29862                   3.0  \n",
       "7221                    8.0  \n",
       "28123                   8.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Simple_reviews= reviews[[\"Target\",\"review_length\",\"review_neg\",\"review_neg_words\",\"review_pos_words\",\"review_Lexicon_score\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(Simple_reviews[[\"review_length\",\"review_neg\",\"review_neg_words\",\"review_pos_words\",\"review_Lexicon_score\"]], Simple_reviews[\"Target\"], test_size=0.4, random_state=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement et test des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 1200) \n",
    "\n",
    "forest = clf.fit( X_train,  y_train)\n",
    "#pred_train = forest3.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58078125000000003"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgsAAAFkCAYAAACuFXjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123626f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = forest.feature_importances_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(importances)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier(n_estimators = 1200) \n",
    "\n",
    "GBM = GB.fit( X_train,  y_train)\n",
    "#pred_train = GBM.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60399999999999998"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'entrainement de SVM est très consommateur de puissance de calcul..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM = svm.SVC(C=1.0, kernel='linear')\n",
    "%time SVM1=SVM.fit( X_train,  y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time SVM1.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "SVM_2 = svm.SVC(C=1.0, kernel='poly')\n",
    "SVM2=SVM_2.fit( X_train,  y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM2.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modèle composé: des features avancés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorisation des données:  Term Centrality-Invese Document Frequency \n",
    "Une méthode de vectorisation du corpus qui \"respecte\" l'ordre des mots dans les phrases en lui accordant un poids correspondant à la centralité du noeud du mot dans le graph des mots des documents, puis le multiplie par la correction IDF qu permet d'éliminer les stopwords (les mots non significatifs qui sont dans tout les textes presque)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### createGraphFeatures Function definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code copié, cf : https://github.com/y3nk0/Graph-Based-TC \n",
    "import networkx as nx\n",
    "import string\n",
    "from sys import maxint\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "import os.path\n",
    "import math\n",
    "from scipy.stats import pearsonr,kendalltau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#===============================================================================\n",
    "# core_Size_Distribution(core_sequence)\n",
    "#===============================================================================\n",
    "def core_Size_Distribution(core_sequence):\n",
    "    \"\"\"\n",
    "    core_Size_Distribution(core_sequence)\n",
    "    The function takes as input the core sequence of a graph and returns the distribution\n",
    "    of the cores' sizes (k-core size vs. k)\n",
    "    \"\"\"\n",
    "\n",
    "    max_core_number = max(core_sequence.values()) #maximum core number\n",
    "\n",
    "    # core_sizes: size of each core indexed by position\n",
    "    (core_sizes, x, y) = plt.hist(core_sequence.values(), bins=max_core_number)\n",
    "\n",
    "    print \"Core sizes:\", core_sizes, \"\\n\"\n",
    "    #print max_core_number\n",
    "\n",
    "    # plot in log-log axis\n",
    "    # x: core size, k    y: number of nodes in k-core\n",
    "    plt.loglog(range(1, len(core_sizes)+1), core_sizes, 'o-', linewidth=2)\n",
    "    plt.xlabel('Core Number, k')\n",
    "    plt.ylabel('Size of Core')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def createGraphFeatures(num_documents,clean_train_documents,unique_words,bigrams,sliding_window,b,idf_par,centrality_par,centrality_col_par,train_par,idf_learned,icw_learned,kcore_par,dGcol_nodes,max_core_col,kcore_par_int,max_core_feat,feature_reduction,avgLen):\n",
    "    features = np.zeros((num_documents,len(unique_words)))\n",
    "    unique_words_len = len(unique_words)\n",
    "    term_num_docs = {}\n",
    "\n",
    "    print \"sliding_window:\"+str(sliding_window)\n",
    "    if train_par:\n",
    "        print \"Training set...\"\n",
    "        idfs = {}\n",
    "        dGcol_nodes = {}\n",
    "        icws = {}\n",
    "        max_core_feat = []\n",
    "\n",
    "        print \"Creating the graph of words for collection...\"\n",
    "\n",
    "        if centrality_col_par==\"pagerank_centrality\" or centrality_col_par==\"in_degree_centrality\" or centrality_col_par==\"out_degree_centrality\" or centrality_col_par==\"closeness_centrality_directed\" or centrality_col_par==\"betweenness_centrality_directed\":\n",
    "            dGcol = nx.DiGraph()\n",
    "        else:\n",
    "            dGcol = nx.Graph()\n",
    "        \n",
    "        totalLen = 0\n",
    "        for i in range( 0,num_documents ):\n",
    "            #dG = nx.Graph()\n",
    "            found_unique_words = []\n",
    "            wordList1 = clean_train_documents[i].split(None)\n",
    "            wordList2 = [string.rstrip(x.lower(), ',.!?;') for x in wordList1]\n",
    "\n",
    "            docLen = len(wordList2)\n",
    "            totalLen += docLen\n",
    "\n",
    "            # print clean_train_documents[i]\n",
    "            if len(wordList2)>1:\n",
    "                for k, word in enumerate(wordList2):\n",
    "\n",
    "                    if word not in found_unique_words:\n",
    "                        found_unique_words.append(word)\n",
    "                        if word not in term_num_docs:\n",
    "                            term_num_docs[word] = 1\n",
    "                        else:\n",
    "                            term_num_docs[word] += 1\n",
    "\n",
    "                    for j in xrange(1,sliding_window):\n",
    "                        try:\n",
    "                            next_word = wordList2[k + j]\n",
    "                            # print word+\"\\t\"+next_word\n",
    "                            # time.sleep(2)\n",
    "                            if not dGcol.has_node(word):\n",
    "                                dGcol.add_node(word)\n",
    "                                dGcol.node[word]['count'] = 1\n",
    "                                \n",
    "                            else:\n",
    "                                dGcol.node[word]['count'] += 1\n",
    "                                \n",
    "                            if not dGcol.has_node(next_word):\n",
    "                                dGcol.add_node(next_word)\n",
    "                                dGcol.node[next_word]['count'] = 0\n",
    "\n",
    "                            if not dGcol.has_edge(word, next_word):\n",
    "                                dGcol.add_edge(word, next_word, weight = 1)\n",
    "                            else:\n",
    "                                dGcol.edge[word][next_word]['weight'] += 1\n",
    "                        except IndexError:\n",
    "                            if not dGcol.has_node(word):\n",
    "                                dGcol.add_node(word)\n",
    "                                dGcol.node[word]['count'] = 1\n",
    "                            else:\n",
    "                                dGcol.node[word]['count'] += 1\n",
    "                        except:\n",
    "                            raise\n",
    "\n",
    "        print \"Number of self-loops for collection graph:\"+str(dGcol.number_of_selfloops())\n",
    "        dGcol.remove_edges_from(dGcol.selfloop_edges())\n",
    "        collection_count_nodes = dGcol.number_of_nodes()\n",
    "        collection_count_edges = dGcol.number_of_edges()\n",
    "        print \"Number of nodes in collection graph:\"+str(collection_count_nodes)\n",
    "        print \"Number of edges in collection graph:\"+str(collection_count_edges)\n",
    "        avgLen = float(totalLen)/num_documents\n",
    "        print \"Average document length:\"+str(avgLen)\n",
    "        \n",
    "   \n",
    "        if idf_par==\"icw\" or idf_par==\"icw+idf\" or idf_par==\"tf-icw\":\n",
    "            icw_col = {}\n",
    "\n",
    "            if(kcore_par==\"A1\" or kcore_par==\"A2\"):\n",
    "                collection_core = nx.core_number(dGcol)\n",
    "                max_core = max(collection_core.values())\n",
    "                print \"Max core of collection:\"+str(max_core)\n",
    "                # core_Size_Distribution(collection_core)\n",
    "                for k,g in enumerate(dGcol.nodes()):\n",
    "                    if kcore_par==\"A1\":\n",
    "                        # A1 method: remove features and then rank\n",
    "                        for x in range(0,kcore_par_int):\n",
    "                            if collection_core[g]==max_core-x:\n",
    "                                dGcol.remove_node(g)\n",
    "                    else:\n",
    "                        # A2 method: rank first and then remove features\n",
    "                        for x in range(0,kcore_par_int):\n",
    "                            if collection_core[g]==max_core-x:\n",
    "                                max_core_col.append(g)\n",
    "\n",
    "\n",
    "            if centrality_col_par == \"degree_centrality\":\n",
    "                centrality_col = nx.degree_centrality(dGcol)\n",
    "            elif centrality_col_par==\"in_degree_centrality\":\n",
    "                centrality_col = nx.in_degree_centrality(dGcol)\n",
    "            elif centrality_col_par==\"out_degree_centrality\":\n",
    "                centrality_col = nx.out_degree_centrality(dGcol)\n",
    "            elif centrality_col_par == \"pagerank_centrality\":\n",
    "                # centrality_col = pg.pagerank(dGcol,max_iter=1000)\n",
    "                centrality_col = nx.pagerank(dGcol)\n",
    "            elif centrality_col_par == \"eigenvector_centrality\":\n",
    "                centrality_col = nx.eigenvector_centrality(dGcol,max_iter=1000)\n",
    "            elif centrality_col_par == \"betweenness_centrality\" or centrality_col_par==\"betweenness_centrality_directed\":\n",
    "                centrality_col = nx.betweenness_centrality(dGcol)\n",
    "            elif centrality_col_par == \"triangles\":\n",
    "                centrality_col = nx.triangles(dGcol)\n",
    "            elif centrality_col_par == \"clustering_coefficient\":\n",
    "                centrality_col = nx.clustering(dGcol)\n",
    "            elif centrality_col_par == \"core_number\":\n",
    "                centrality_col = nx.core_number(dGcol)\n",
    "            elif centrality_col_par == \"closeness_centrality\" or centrality_col_par==\"closeness_centrality_directed\":\n",
    "                centrality_col = nx.closeness_centrality(dGcol)\n",
    "            elif centrality_col_par == \"closeness_centrality_weighted\":\n",
    "                centrality_col = nx.closeness_centrality(dGcol)\n",
    "            elif centrality_col_par == \"communicability_centrality\":\n",
    "                centrality_col = nx.communicability_centrality(dGcol)\n",
    "\n",
    "            centr_sum = sum(centrality_col.values())\n",
    "            for k,g in enumerate(dGcol.nodes()):\n",
    "                if centrality_col[g]!=0:\n",
    "                    if idf_par==\"icw\" or idf_par==\"tf-icw\" or idf_par==\"icw+idf\":\n",
    "                        icw_col[g] = math.log10(float(centr_sum)/centrality_col[g])\n",
    "                else:\n",
    "                    icw_col[g] = 0\n",
    "\n",
    "        # elif idf_par==\"idf\":\n",
    "        idf_col = {}\n",
    "        for x in term_num_docs:\n",
    "            if idf_par==\"idf\":\n",
    "                idf_col[x] = math.log10((float(num_documents)+1.0) / term_num_docs[x])\n",
    "            elif idf_par==\"icw+idf\":\n",
    "                idf_col[x] = math.log10((float(num_documents)+1.0) / term_num_docs[x])\n",
    "\n",
    "        dGcol_nodes = dGcol.nodes()\n",
    "\n",
    "    # for the testing set\n",
    "    else:\n",
    "\n",
    "        if idf_par==\"idf\":\n",
    "            idf_col = idf_learned\n",
    "        elif idf_par==\"icw\" or idf_par==\"tf-icw\":\n",
    "            icw_col = icw_learned\n",
    "        elif idf_par==\"icw+idf\":\n",
    "            idf_col = idf_learned\n",
    "            icw_col = icw_learned\n",
    "\n",
    "        collection_count_nodes = 0\n",
    "        collection_count_edges = 0\n",
    "\n",
    "    # nx.write_edgelist(dGcol,\"test.edgelist\",data=True,delimiter=\"\\t\")\n",
    "\n",
    "    print \"Creating the graph of words for each document...\"\n",
    "    totalNodes = 0\n",
    "    totalEdges = 0\n",
    "\n",
    "    corrs_per_category = [[] for i in range(4)]\n",
    "\n",
    "    for i in range( 0,num_documents ):\n",
    "\n",
    "        if centrality_par==\"pagerank_centrality\" or centrality_par==\"in_degree_centrality\" or centrality_par==\"out_degree_centrality\" or centrality_par==\"closeness_centrality_directed\" or centrality_par==\"betweenness_centrality_directed\":\n",
    "            dG = nx.DiGraph()\n",
    "        else:\n",
    "            dG = nx.Graph()\n",
    "\n",
    "        wordList1 = clean_train_documents[i].split(None)\n",
    "        wordList2 = [string.rstrip(x.lower(), ',.!?;') for x in wordList1]\n",
    "        docLen = len(wordList2)\n",
    "\n",
    "        if len(wordList2)>1:\n",
    "            for k, word in enumerate(wordList2):\n",
    "                for j in xrange(1,sliding_window):\n",
    "                    try:\n",
    "                        next_word = wordList2[k + j]\n",
    "                        \n",
    "                        if not dG.has_node(word):\n",
    "                            dG.add_node(word)\n",
    "                            dG.node[word]['count'] = 1\n",
    "                        else:\n",
    "                            dG.node[word]['count'] += 1\n",
    "\n",
    "                        if not dG.has_node(next_word):\n",
    "                            dG.add_node(next_word)\n",
    "                            dG.node[next_word]['count'] = 1\n",
    "\n",
    "                        if not dG.has_edge(word, next_word):\n",
    "                            dG.add_edge(word, next_word, weight = 1)\n",
    "                        else:\n",
    "                            dG.edge[word][next_word]['weight'] += 1\n",
    "                    except IndexError:\n",
    "                        if not dG.has_node(word):\n",
    "                            dG.add_node(word)\n",
    "                            dG.node[word]['count'] = 1\n",
    "                        else:\n",
    "                            dG.node[word]['count'] += 1\n",
    "                    except:\n",
    "                        raise\n",
    "\n",
    "            dG.remove_edges_from(dG.selfloop_edges())\n",
    "            for node1, node2 in dG.edges_iter():\n",
    "                dG.edge[node1][node2]['inv_weight'] = 1.0 / dG.edge[node1][node2]['weight']\n",
    "\n",
    "            if train_par:\n",
    "                if(kcore_par==\"B1\" or kcore_par==\"B2\"):\n",
    "                    max_core_doc = []\n",
    "                    document_core = nx.core_number(dG)\n",
    "                    max_core = max(document_core.values())\n",
    "                    # print \"Max core of document:\"+str(max_core)\n",
    "                    # core_Size_Distribution(document_core)\n",
    "                    for k,g in enumerate(dG.nodes()):\n",
    "                        if kcore_par==\"B1\":\n",
    "                            # B1 method: remove features and then rank\n",
    "                            for x in range(0,kcore_par_int):\n",
    "                                if document_core[g]==max_core-x:\n",
    "                                    dG.remove_node(g)\n",
    "                        else:\n",
    "                            # B2 method: rank first and then remove features\n",
    "                            for x in range(0,kcore_par_int):\n",
    "                                if document_core[g]==max_core-x:\n",
    "                                    max_core_doc.append(g)\n",
    "                                    if g not in max_core_feat:\n",
    "                                        max_core_feat.append(g)\n",
    "            \n",
    "            # centrality = nx.degree_centrality(dG)\n",
    "            #centrality = nx.core_number(dG)\n",
    "            if centrality_par == \"degree_centrality\":\n",
    "                centrality = nx.degree_centrality(dG)\n",
    "            elif centrality_par == \"in_degree_centrality\":\n",
    "                centrality = nx.in_degree_centrality(dG)\n",
    "            elif centrality_par == \"out_degree_centrality\":\n",
    "                centrality = nx.out_degree_centrality(dG)\n",
    "            elif centrality_par == \"pagerank_centrality\":\n",
    "                # centrality = pg.pagerank(dG,max_iter=1000)\n",
    "                centrality = nx.pagerank(dG)\n",
    "            elif centrality_par ==\"betweenness_centrality\" or centrality_par==\"betweenness_centrality_directed\":\n",
    "                centrality = nx.betweenness_centrality(dG,weight=\"weight\")\n",
    "            elif centrality_par ==\"triangles\":\n",
    "                centrality = nx.triangles(dG)\n",
    "            elif centrality_par ==\"eigenvector_centrality\":\n",
    "                centrality = nx.eigenvector_centrality_numpy(dG)\n",
    "            elif centrality_par ==\"core_number\":\n",
    "                centrality = nx.core_number(dG)\n",
    "            elif centrality_par ==\"clustering_coefficient\":\n",
    "                centrality = nx.clustering(dG)\n",
    "            elif centrality_par == \"closeness_centrality\" or centrality_par==\"closeness_centrality_directed\":\n",
    "                centrality = nx.closeness_centrality(dG)\n",
    "            elif centrality_par == \"closeness_centrality_weighted\":\n",
    "                centrality = nx.closeness_centrality(dG,distance='weight')\n",
    "            elif centrality_par == \"communicability_centrality\":\n",
    "                centrality = nx.communicability_centrality(dG)\n",
    "            elif centrality_par == \"closeness_centrality_not_normalized\":\n",
    "                centrality = nx.closeness_centrality(dG,normalized=False)\n",
    "            elif centrality_par == \"degree_centrality_weighted\":\n",
    "                centrality = weighted_degree_centrality(dG)\n",
    "            #print \"Number of self-loops:\"+str(dG.number_of_selfloops())\n",
    "            #centrality = nx.out_degree_centrality(dG)\n",
    "            #centrality = pg.pagerank(dG,max_iter=1000)\n",
    "            #centrality = nx.katz_centrality(dG,max_iter=10000)\n",
    "\n",
    "            totalNodes += dG.number_of_nodes()\n",
    "            totalEdges += dG.number_of_edges()\n",
    "\n",
    "            tfs = []\n",
    "            centralities = []\n",
    "            centr_sum_doc = sum(centrality.values())\n",
    "\n",
    "            for k, g in enumerate(dG.nodes()):\n",
    "                if g in dGcol_nodes:\n",
    "                    if kcore_par==\"B2\":\n",
    "                        if g in max_core_feat:\n",
    "                            # Degree centrality (local feature)\n",
    "                            if g in unique_words:\n",
    "                                #features[i,unique_words.index(g)] = dG.degree(nbunch=g,weight='weight') * idf_col[g]\n",
    "                                if idf_par==\"no\":\n",
    "                                    features[i,unique_words.index(g)] = centrality[g]/(1-b+(b*(float(docLen)/avgLen)))\n",
    "                                elif idf_par==\"idf\":\n",
    "                                    features[i,unique_words.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * idf_col[g]\n",
    "                                    # features[i,unique_words.index(g)] = centrality[g] * idf_col[g]\n",
    "                                elif idf_par==\"icw\":\n",
    "                                    features[i,unique_words.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g]\n",
    "                                    # features[i,unique_words.index(g)] = centrality[g] * icw_col[g]\n",
    "                                elif idf_par==\"icw+idf\":\n",
    "                                    features[i,unique_words.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g] * idf_col[g]\n",
    "                                    # features[i,unique_words.index(g)] = centrality[g] * math.log10(icw_col[g] * idf_col[g])\n",
    "\n",
    "                            elif g in bigrams:\n",
    "                                #features[i,unique_words.index(g)] = dG.degree(nbunch=g,weight='weight') * idf_col[g]\n",
    "                                if idf_par==\"no\":\n",
    "                                    features[i,unique_words_len+bigrams.index(g)] = centrality[g]/(1-b+(b*(float(docLen)/avgLen)))\n",
    "                                elif idf_par==\"idf\":\n",
    "                                    features[i,unique_words_len+bigrams.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * idf_col[g]\n",
    "                                    # features[i,unique_words.index(g)] = centrality[g] * idf_col[g]\n",
    "                                elif idf_par==\"icw\":\n",
    "                                    features[i,unique_words_len+bigrams.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g]\n",
    "                                    # features[i,unique_words.index(g)] = centrality[g] * icw_col[g]\n",
    "                                elif idf_par==\"icw+idf\":\n",
    "                                    features[i,unique_words_len+bigrams.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g] * idf_col[g]\n",
    "                                    # features[i,unique_words.index(g)] = centrality[g] * math.log10(icw_col[g] * idf_col[g])\n",
    "                    else:\n",
    "                        if g in unique_words:\n",
    "                            #features[i,unique_words.index(g)] = dG.degree(nbunch=g,weight='weight') * idf_col[g]\n",
    "                            if idf_par==\"no\":\n",
    "                                features[i,unique_words.index(g)] = centrality[g]/(1-b+(b*(float(docLen)/avgLen)))\n",
    "                                tfs.append(wordList2.count(g))\n",
    "                                centralities.append(centrality[g])\n",
    "                            elif idf_par==\"tf-icw\":\n",
    "                                tf_g = 1+math.log(1+math.log(wordList2.count(g)))\n",
    "                                features[i,unique_words.index(g)] = (tf_g/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g]\n",
    "                            elif idf_par==\"idf\":\n",
    "                                features[i,unique_words.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * idf_col[g]\n",
    "                                # features[i,unique_words.index(g)] = centrality[g] * idf_col[g]\n",
    "                            elif idf_par==\"icw\":\n",
    "                                features[i,unique_words.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g]\n",
    "                                # features[i,unique_words.index(g)] = centrality[g] * icw_col[g]\n",
    "                            elif idf_par==\"icw+idf\":\n",
    "                                features[i,unique_words.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g] * idf_col[g]\n",
    "                                # features[i,unique_words.index(g)] = centrality[g] * math.log10(icw_col[g] * idf_col[g])\n",
    "\n",
    "                        elif g in bigrams:\n",
    "                            #features[i,unique_words.index(g)] = dG.degree(nbunch=g,weight='weight') * idf_col[g]\n",
    "                            if idf_par==\"no\":\n",
    "                                features[i,unique_words_len+bigrams.index(g)] = centrality[g]/(1-b+(b*(float(docLen)/avgLen)))\n",
    "                            elif idf_par==\"idf\":\n",
    "                                features[i,unique_words_len+bigrams.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * idf_col[g]\n",
    "                                # features[i,unique_words.index(g)] = centrality[g] * idf_col[g]\n",
    "                            elif idf_par==\"icw\":\n",
    "                                features[i,unique_words_len+bigrams.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g]\n",
    "                                # features[i,unique_words.index(g)] = centrality[g] * icw_col[g]\n",
    "                            elif idf_par==\"icw+idf\":\n",
    "                                features[i,unique_words_len+bigrams.index(g)] = (centrality[g]/(1-b+(b*(float(docLen)/avgLen)))) * icw_col[g] * idf_col[g]\n",
    "                                # features[i,unique_words.index(g)] = centrality[g] * math.log10(icw_col[g] * idf_col[g])\n",
    "    #     if train_par:\n",
    "    #         # pears = pearsonr(tfs,centralities)\n",
    "\n",
    "    #         ind_tfs = sorted(range(len(tfs)), key=lambda k: tfs[k])[-20:]\n",
    "    #         ind_centr = sorted(range(len(centralities)), key=lambda k: centralities[k])[-20:]\n",
    "    #         tau, p_value = kendalltau([unique_words[k] for k in ind_tfs],[unique_words[k] for k in ind_centr])\n",
    "            \n",
    "    #         corrs_per_category[int(y[i])-1].append(tau)\n",
    "    \n",
    "    # if train_par:\n",
    "\n",
    "    #     text_file = open(\"kendal_tfs_tws_output_tw_idf_\"+idf_par+\"_centr_\"+centrality_par+\"_sliding_\"+str(sliding_window)+\"_kcore_\"+kcore_par+\".txt\", \"w\")\n",
    "        \n",
    "    #     text_file.write(str(corrs_per_category))\n",
    "    #     text_file.close()\n",
    "\n",
    "    #     fig = plt.figure()\n",
    "    #     ax = fig.add_subplot(111)\n",
    "\n",
    "    #     ax.boxplot(corrs_per_category[:])\n",
    "\n",
    "    #     plt.show()\n",
    "\n",
    "\n",
    "    if idf_par==\"no\":\n",
    "        idfs = {}\n",
    "        icws = {}\n",
    "    if idf_par==\"idf\":\n",
    "        idfs = idf_col\n",
    "        icws = {}\n",
    "    elif idf_par==\"icw\" or idf_par==\"tf-icw\":\n",
    "        idfs = {}\n",
    "        icws = icw_col\n",
    "    elif idf_par==\"icw+idf\":\n",
    "        idfs = idf_col\n",
    "        icws = icw_col\n",
    "\n",
    "    if train_par:\n",
    "        if kcore_par==\"B2\":\n",
    "            feature_reduction = float(len(max_core_feat))/len(dGcol_nodes)\n",
    "            print \"Percentage of features kept:\"+str(feature_reduction)\n",
    "        print \"Average number of nodes:\"+str(float(totalNodes)/num_documents)\n",
    "        print \"Average number of edges:\"+str(float(totalEdges)/num_documents)\n",
    "    \n",
    "    return features, idfs,icws,collection_count_nodes, collection_count_edges, dGcol_nodes,max_core_col,feature_reduction, max_core_feat,avgLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reviews[\"review_stemmed\"], reviews[\"Target\"], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13373    corpse killer 3do jeu tir deroulant comme film...\n",
       "4056     c pink floyd ! ca suffit savoir qu'il l'album ...\n",
       "29862    belle alure tre belle fourche couleur belle co...\n",
       "7221     tres bon produit,surtout debut l'allaitement.l...\n",
       "28123    trees bon telephone enormement d'option tres d...\n",
       "Name: review_stemmed, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=3000\n",
    "clean_train_documents = list(X_train)[:N]\n",
    "num_documents=len(clean_train_documents)\n",
    "unique_words = list(set((\" \".join(clean_train_documents).split())))\n",
    "bigrams = []\n",
    "sliding_window=2\n",
    "b = 0.03\n",
    "idf_par = \"idf\"\n",
    "centrality_par = \"betweenness_centrality_directed\"\n",
    "centrality_col_par=centrality_par\n",
    "idfs = {}\n",
    "icws = {}\n",
    "kcore_par = \"A0\"\n",
    "dGcol_nodes = {}\n",
    "max_core_col = []\n",
    "kcore_par_int = 1\n",
    "max_core_feat = []\n",
    "feature_reduction = 0.0\n",
    "avgLen = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliding_window:2\n",
      "Training set...\n",
      "Creating the graph of words for collection...\n",
      "Number of self-loops for collection graph:37\n",
      "Number of nodes in collection graph:14504\n",
      "Number of edges in collection graph:46037\n",
      "Average document length:19.6166666667\n",
      "Creating the graph of words for each document...\n",
      "Average number of nodes:18.0953333333\n",
      "Average number of edges:18.4336666667\n"
     ]
    }
   ],
   "source": [
    "features, idfs_learned,icws_learned,collection_count_nodes, collection_count_edges, dGcol_nodes,max_core_col,feature_reduction, max_core_feat,avgLen = createGraphFeatures(num_documents,clean_train_documents,unique_words,bigrams,sliding_window,b,idf_par,centrality_par,centrality_col_par,True,idfs,icws,kcore_par,dGcol_nodes,max_core_col,kcore_par_int,max_core_feat,feature_reduction,avgLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 17616)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement et test des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliding_window:2\n",
      "Creating the graph of words for each document...\n"
     ]
    }
   ],
   "source": [
    "N_test=500\n",
    "clean_test_documents = list(X_test[:N_test])\n",
    "num_test_documents=len(clean_test_documents)\n",
    "test_features,idfs,icws,collection_count_nodes, collection_count_edges, dGcol_nodes,max_core_col,feature_reduction, max_core_feat,avgLen = createGraphFeatures(num_test_documents,clean_test_documents,unique_words,bigrams,sliding_window,b,idf_par,centrality_par,centrality_col_par,False,idfs_learned,icws_learned,kcore_par,dGcol_nodes,max_core_col,kcore_par_int,max_core_feat,feature_reduction,avgLen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_2 = RandomForestClassifier(n_estimators = 500) \n",
    "\n",
    "forest_2 = clf_2.fit( features, y_train [:N])\n",
    "#pred_train = forest.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59799999999999998"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_2.score(test_features, y_test[:N_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAFkCAYAAAAKf8APAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN9BcbvvgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13ce37c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances_2 = forest_2.feature_importances_\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(importances_2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les mots les plus important dans les arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'tres'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words[list(importances_2).index(max(importances_2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'bon'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=list(importances_2)\n",
    "\n",
    "l[list(importances_2).index(max(importances_2))]=0\n",
    "\n",
    "unique_words[l.index(max(l))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'qualite'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2=l\n",
    "\n",
    "l2[l.index(max(l))]=0\n",
    "\n",
    "unique_words[l2.index(max(l2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.  Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB2 = GradientBoostingClassifier(n_estimators = 500) \n",
    "\n",
    "GBM2 = GB2.fit( features, y_train [:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55200000000000005"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM2.score(test_features, y_test[:N_test]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles hybrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(reviews[[\"review_stemmed\",\"review_neg\",\"review_Lexicon_score\",\"review_length\"]], reviews[\"Target\"], test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=3000\n",
    "clean_train_documents = list(X_train1[\"review_stemmed\"])[:N]\n",
    "num_documents=len(clean_train_documents)\n",
    "unique_words = list(set((\" \".join(clean_train_documents).split())))\n",
    "bigrams = []\n",
    "sliding_window=2\n",
    "b = 0.03\n",
    "idf_par = \"idf\"\n",
    "centrality_par = \"betweenness_centrality_directed\"\n",
    "centrality_col_par=centrality_par\n",
    "idfs = {}\n",
    "icws = {}\n",
    "kcore_par = \"A0\"\n",
    "dGcol_nodes = {}\n",
    "max_core_col = []\n",
    "kcore_par_int = 1\n",
    "max_core_feat = []\n",
    "feature_reduction = 0.0\n",
    "avgLen = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliding_window:2\n",
      "Training set...\n",
      "Creating the graph of words for collection...\n",
      "Number of self-loops for collection graph:37\n",
      "Number of nodes in collection graph:14504\n",
      "Number of edges in collection graph:46037\n",
      "Average document length:19.6166666667\n",
      "Creating the graph of words for each document...\n",
      "Average number of nodes:18.0953333333\n",
      "Average number of edges:18.4336666667\n"
     ]
    }
   ],
   "source": [
    "features, idfs_learned,icws_learned,collection_count_nodes, collection_count_edges, dGcol_nodes,max_core_col,feature_reduction, max_core_feat,avgLen = createGraphFeatures(num_documents,clean_train_documents,unique_words,bigrams,sliding_window,b,idf_par,centrality_par,centrality_col_par,True,idfs,icws,kcore_par,dGcol_nodes,max_core_col,kcore_par_int,max_core_feat,feature_reduction,avgLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=X_train1[[\"review_neg\",\"review_Lexicon_score\",\"review_length\"]][:N]\n",
    "\n",
    "df1=pd.DataFrame(features, columns=unique_words, index=df.index)\n",
    "\n",
    "X_train_DF=pd.concat([df, df1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_neg</th>\n",
       "      <th>review_Lexicon_score</th>\n",
       "      <th>review_length</th>\n",
       "      <th>....bien</th>\n",
       "      <th>contresens</th>\n",
       "      <th>miel,</th>\n",
       "      <th>equipe....</th>\n",
       "      <th>rennais</th>\n",
       "      <th>four</th>\n",
       "      <th>fous</th>\n",
       "      <th>...</th>\n",
       "      <th>moderation</th>\n",
       "      <th>epousent</th>\n",
       "      <th>35ml</th>\n",
       "      <th>experient</th>\n",
       "      <th>volumes</th>\n",
       "      <th>plaignent</th>\n",
       "      <th>tonnes</th>\n",
       "      <th>l'autofocus</th>\n",
       "      <th>prochaine</th>\n",
       "      <th>decalques.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13373</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29862</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28123</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17619 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_neg  review_Lexicon_score  review_length  ....bien  contresens  \\\n",
       "13373           0                   4.0            275       0.0         0.0   \n",
       "4056            0                   0.0             65       0.0         0.0   \n",
       "29862           0                   3.0            276       0.0         0.0   \n",
       "7221            1                   8.0            134       0.0         0.0   \n",
       "28123           0                   8.0             52       0.0         0.0   \n",
       "\n",
       "       miel,  equipe....  rennais  four  fous     ...      moderation  \\\n",
       "13373    0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "4056     0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "29862    0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "7221     0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "28123    0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "\n",
       "       epousent  35ml  experient  volumes  plaignent  tonnes  l'autofocus  \\\n",
       "13373       0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "4056        0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "29862       0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "7221        0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "28123       0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "\n",
       "       prochaine  decalques.  \n",
       "13373        0.0         0.0  \n",
       "4056         0.0         0.0  \n",
       "29862        0.0         0.0  \n",
       "7221         0.0         0.0  \n",
       "28123        0.0         0.0  \n",
       "\n",
       "[5 rows x 17619 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliding_window:2\n",
      "Creating the graph of words for each document...\n"
     ]
    }
   ],
   "source": [
    "N_test=500\n",
    "clean_test_documents = list(X_test1[\"review_stemmed\"])[:N_test]\n",
    "num_test_documents=len(clean_test_documents)\n",
    "test_features2,idfs,icws,collection_count_nodes, collection_count_edges, dGcol_nodes,max_core_col,feature_reduction, max_core_feat,avgLen = createGraphFeatures(num_test_documents,clean_test_documents,unique_words,bigrams,sliding_window,b,idf_par,centrality_par,centrality_col_par,False,idfs_learned,icws_learned,kcore_par,dGcol_nodes,max_core_col,kcore_par_int,max_core_feat,feature_reduction,avgLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_neg</th>\n",
       "      <th>review_Lexicon_score</th>\n",
       "      <th>review_length</th>\n",
       "      <th>....bien</th>\n",
       "      <th>contresens</th>\n",
       "      <th>miel,</th>\n",
       "      <th>equipe....</th>\n",
       "      <th>rennais</th>\n",
       "      <th>four</th>\n",
       "      <th>fous</th>\n",
       "      <th>...</th>\n",
       "      <th>moderation</th>\n",
       "      <th>epousent</th>\n",
       "      <th>35ml</th>\n",
       "      <th>experient</th>\n",
       "      <th>volumes</th>\n",
       "      <th>plaignent</th>\n",
       "      <th>tonnes</th>\n",
       "      <th>l'autofocus</th>\n",
       "      <th>prochaine</th>\n",
       "      <th>decalques.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30661</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63191</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38241</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17619 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_neg  review_Lexicon_score  review_length  ....bien  contresens  \\\n",
       "7389            0                   0.0             66       0.0         0.0   \n",
       "3509            0                   3.0            268       0.0         0.0   \n",
       "30661           0                   6.0             39       0.0         0.0   \n",
       "63191           0                   0.0             88       0.0         0.0   \n",
       "38241           0                   0.0             40       0.0         0.0   \n",
       "\n",
       "       miel,  equipe....  rennais  four  fous     ...      moderation  \\\n",
       "7389     0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "3509     0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "30661    0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "63191    0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "38241    0.0         0.0      0.0   0.0   0.0     ...             0.0   \n",
       "\n",
       "       epousent  35ml  experient  volumes  plaignent  tonnes  l'autofocus  \\\n",
       "7389        0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "3509        0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "30661       0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "63191       0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "38241       0.0   0.0        0.0      0.0        0.0     0.0          0.0   \n",
       "\n",
       "       prochaine  decalques.  \n",
       "7389         0.0         0.0  \n",
       "3509         0.0         0.0  \n",
       "30661        0.0         0.0  \n",
       "63191        0.0         0.0  \n",
       "38241        0.0         0.0  \n",
       "\n",
       "[5 rows x 17619 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=X_test1[[\"review_neg\",\"review_Lexicon_score\",\"review_length\"]][:N_test]\n",
    "df1=pd.DataFrame(test_features2, columns=unique_words, index=df.index)\n",
    "X_test_DF=pd.concat([df, df1], axis=1)\n",
    "X_test_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB3 = GradientBoostingClassifier(n_estimators = 1200) \n",
    "\n",
    "GBM3 = GB3.fit(X_train_DF, y_train1[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60999999999999999"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM3.score(X_test_DF, y_test1[:N_test]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(n_estimators = 1200) \n",
    "\n",
    "forest3 = clf3.fit( X_train_DF, y_train1[:N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60399999999999998"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest3.score(X_test_DF, y_test1[:N_test]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# => Un score de 61% pour seulement 3000 lignes d'entraiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nous avons atteind 64% pour 10000"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
